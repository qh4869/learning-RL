### 心得 ###

- sarsa相比q learning更依靠初始的随机结果，如果初始的结果不好，它就非常保守，初始结果好，它就很快收敛到最优（有可能局部最优）
- lambda越大上面的特性体现就越明显



### 遗留 ###

- 对trace路径上的q值更新的时候，error以最后一步为准（标量）向前传递，还是以最后的reward为准（error是矩阵）向前传递，
- 莫烦的代码是以scale传递的，不知道这里有没有什么说法，性能上暂时看不出来
- 莫烦的代码在乘lambda的时候也乘了gamma，这里不知道有什么物理意义，可能跟文献有关

